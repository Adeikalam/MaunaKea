{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten, Dropout, GaussianNoise\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "path = \"D:/MaunaKea/TrainingSetImagesDir/\"\n",
    "patients = {}\n",
    "\n",
    "# Creer un dict avec tous les paths des images par patient\n",
    "for i in range(61):\n",
    "    patients[str(i)] = []\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith(\"_\" + str(i) + \".png\"):\n",
    "            patients[str(i)] += [file]\n",
    "\n",
    "# creer un json pour recup√©rer le dict apres\n",
    "with open('unsorted_patients.txt', 'w') as json_file:\n",
    "    json.dump(patients, json_file)\n",
    "\n",
    "targets = pd.read_csv(\"train_target.csv\")\n",
    "targets['patient'] = targets['image_filename'].map(lambda x: x.partition('_')[-1].partition('_')[-1].partition('.')[0])\n",
    "targets = targets.sort_values(by = ['patient', 'image_filename']).set_index(keys = ['image_filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(patients.keys())\n",
    "for key in keys:\n",
    "    if (patients[key] == []):\n",
    "        patients.pop(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = targets.loc[patients['10'] + patients['8'] + patients['7'] + patients['6']]# + patients['1'] + patients['0']]\n",
    "training_set = targets.drop(validation_set.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_training_path = \"D:/MaunaKea/TrainingSetImagesDir/\"\n",
    "small_training_images = np.zeros((training_set.shape[0], 224,224, 3))\n",
    "small_training_classes = np.zeros(training_set.shape[0])\n",
    "\n",
    "small_validation_path = \"D:/MaunaKea/TrainingSetImagesDir/\"\n",
    "small_validation_images = np.zeros((validation_set.shape[0], 224, 224, 3))\n",
    "small_validation_classes = np.zeros(validation_set.shape[0])\n",
    "\n",
    "i = 0\n",
    "for image_path in training_set.index:\n",
    "    small_training_images[i] = cv2.resize(cv2.imread(small_training_path + image_path), (224, 224))\n",
    "    #small_training_images[i] = preprocess_input(small_training_images[i])\n",
    "    small_training_classes[i] = training_set.iloc[i]['class_number']\n",
    "    i += 1\n",
    "    \n",
    "i = 0\n",
    "for image_path in validation_set.index:\n",
    "    small_validation_images[i] = cv2.resize(cv2.imread(small_validation_path + image_path), (224, 224))\n",
    "    small_validation_images[i] = preprocess_input(small_validation_images[i])\n",
    "    small_validation_classes[i] = validation_set.iloc[i]['class_number']\n",
    "    i += 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "small_training_classes = to_categorical(small_training_classes)\n",
    "small_validation_classes = to_categorical(small_validation_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1024)              25691136  \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 4)                 4100      \n",
      "=================================================================\n",
      "Total params: 41,467,716\n",
      "Trainable params: 26,748,932\n",
      "Non-trainable params: 14,718,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "base_model = VGG16(include_top = False, input_shape = small_training_images.shape[1:], weights = 'imagenet')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# input1 = Input(shape = small_training_images.shape[1:])\n",
    "# x = GaussianNoise(0.05)(input1)\n",
    "x = base_model(input1)\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(1024, kernel_initializer = 'glorot_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(1024, kernel_initializer = 'glorot_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(4, kernel_initializer = 'glorot_normal', activation = 'softmax')(x)\n",
    "\n",
    "model = Model(inputs = input1, outputs = x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range = 180,\n",
    "   #                          brightness_range = [0.8, 1.2],\n",
    "                             width_shift_range = 30,\n",
    "                             height_shift_range = 30,\n",
    "                             zoom_range = [1.0, 1.2],\n",
    "                             preprocessing_function = preprocess_input,\n",
    "                             horizontal_flip = True,\n",
    "                             vertical_flip = True)\n",
    "#datagen.fit(small_training_images)\n",
    "#sdds = datagen.standardize(small_validation_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "133/132 [==============================] - 54s 403ms/step - loss: 0.9887 - acc: 0.6245 - val_loss: 1.1627 - val_acc: 0.4133\n",
      "Epoch 2/20\n",
      "133/132 [==============================] - 49s 371ms/step - loss: 0.6909 - acc: 0.7376 - val_loss: 0.5717 - val_acc: 0.7487\n",
      "Epoch 3/20\n",
      "133/132 [==============================] - 50s 372ms/step - loss: 0.5837 - acc: 0.7827 - val_loss: 0.5840 - val_acc: 0.7497\n",
      "Epoch 4/20\n",
      "133/132 [==============================] - 49s 370ms/step - loss: 0.5262 - acc: 0.8050 - val_loss: 0.5098 - val_acc: 0.7928\n",
      "Epoch 5/20\n",
      "133/132 [==============================] - 49s 372ms/step - loss: 0.4694 - acc: 0.8266 - val_loss: 0.6564 - val_acc: 0.7169\n",
      "Epoch 6/20\n",
      "133/132 [==============================] - 49s 368ms/step - loss: 0.4680 - acc: 0.8346 - val_loss: 0.5256 - val_acc: 0.7826\n",
      "Epoch 7/20\n",
      "133/132 [==============================] - 50s 374ms/step - loss: 0.4149 - acc: 0.8461 - val_loss: 0.7045 - val_acc: 0.7077\n",
      "Epoch 8/20\n",
      "133/132 [==============================] - 50s 374ms/step - loss: 0.4100 - acc: 0.8502 - val_loss: 0.4972 - val_acc: 0.7938\n",
      "Epoch 9/20\n",
      "133/132 [==============================] - 50s 375ms/step - loss: 0.4109 - acc: 0.8543 - val_loss: 0.2907 - val_acc: 0.8903\n",
      "Epoch 10/20\n",
      "133/132 [==============================] - 50s 373ms/step - loss: 0.3648 - acc: 0.8694 - val_loss: 0.4478 - val_acc: 0.8185\n",
      "Epoch 11/20\n",
      "133/132 [==============================] - 50s 374ms/step - loss: 0.3627 - acc: 0.8675 - val_loss: 0.4756 - val_acc: 0.8062\n",
      "Epoch 12/20\n",
      "133/132 [==============================] - 49s 370ms/step - loss: 0.3895 - acc: 0.8614 - val_loss: 0.5310 - val_acc: 0.7826\n",
      "Epoch 13/20\n",
      "133/132 [==============================] - 50s 374ms/step - loss: 0.3339 - acc: 0.8783 - val_loss: 0.6186 - val_acc: 0.7374\n",
      "Epoch 14/20\n",
      "133/132 [==============================] - 50s 373ms/step - loss: 0.3384 - acc: 0.8762 - val_loss: 0.5233 - val_acc: 0.7610\n",
      "Epoch 15/20\n",
      "133/132 [==============================] - 50s 374ms/step - loss: 0.3214 - acc: 0.8818 - val_loss: 0.3609 - val_acc: 0.8441\n",
      "Epoch 16/20\n",
      "133/132 [==============================] - 50s 373ms/step - loss: 0.3062 - acc: 0.8873 - val_loss: 0.3360 - val_acc: 0.8585\n",
      "Epoch 17/20\n",
      "133/132 [==============================] - 50s 377ms/step - loss: 0.3118 - acc: 0.8851 - val_loss: 0.3228 - val_acc: 0.8656\n",
      "Epoch 18/20\n",
      "133/132 [==============================] - 50s 372ms/step - loss: 0.2826 - acc: 0.8973 - val_loss: 0.3358 - val_acc: 0.8585\n",
      "Epoch 19/20\n",
      "133/132 [==============================] - 50s 373ms/step - loss: 0.3030 - acc: 0.8903 - val_loss: 0.3093 - val_acc: 0.8677\n",
      "Epoch 20/20\n",
      "133/132 [==============================] - 49s 370ms/step - loss: 0.3049 - acc: 0.8891 - val_loss: 0.3526 - val_acc: 0.8410\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "batch_size = 32\n",
    "n_epochs = 20\n",
    "\n",
    "optimizer = Adam(lr = lr)\n",
    "lr_reducer = ReduceLROnPlateau(factor=0.1,\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-7)\n",
    "\n",
    "callbacks = [lr_reducer]\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "history = model.fit_generator(datagen.flow(small_training_images, small_training_classes, batch_size),\n",
    "                                  steps_per_epoch = small_training_images.shape[0]/(batch_size * 2), epochs = n_epochs,\n",
    "                                  validation_data = (small_validation_images, small_validation_classes),\n",
    "                                  callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"vgg16_augmented_nornal_images_no_denoised_85_val_acc.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "small_training_path = \"D:/MaunaKea/Train/\"\n",
    "small_training_images = np.zeros((training_set.shape[0], 224, 224, 3))\n",
    "small_training_classes = np.zeros(training_set.shape[0])\n",
    "\n",
    "small_validation_path = \"D:/MaunaKea/Train/\"\n",
    "small_validation_images = np.zeros((validation_set.shape[0], 224, 224, 3))\n",
    "small_validation_classes = np.zeros(validation_set.shape[0])\n",
    "\n",
    "i = 0\n",
    "for image_path in training_set.index:\n",
    "    small_training_images[i] = cv2.resize(cv2.imread(small_training_path + image_path), (224, 224))\n",
    "    small_training_images[i] = preprocess_input(small_training_images[i])\n",
    "    small_training_classes[i] = training_set.iloc[i]['class_number']\n",
    "    i += 1\n",
    "    \n",
    "i = 0\n",
    "for image_path in validation_set.index:\n",
    "    small_validation_images[i] = cv2.resize(cv2.imread(small_validation_path + image_path), (224,224))\n",
    "    small_validation_images[i] = preprocess_input(small_validation_images[i])\n",
    "    small_validation_classes[i] = validation_set.iloc[i]['class_number']\n",
    "    i += 1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
